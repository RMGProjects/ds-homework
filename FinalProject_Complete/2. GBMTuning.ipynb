{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ++++++++++++++++++++++++++++++\n",
    "# Prudential Life Insurance Assessment\n",
    "# ++++++++++++++++++++++++++++++\n",
    "\n",
    "## Part 2: Train a GBM Model\n",
    "## ----------------------------------------------\n",
    "\n",
    "Author: <a href='mailto:rory_creedon@swissre.com'>Rory Creedon</a><br/>\n",
    "Date: September 2017 <br/>\n",
    "Purpose: To train gradient boosting machine model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction to Boosting\n",
    "\n",
    "Boosting is a \"forward learning\" decision tree model that grows trees sequentially using information from from the trees grown previously. \n",
    "\n",
    "The idea behind boosting is the results of a weak learner (that is a decision tree that generates predictions that are only slightly better than chance) can be filtered into correct predicitons, and the residuals (errors). A decision tree is then fit to these residuals. This tree is then added to the previous tree, the residuals updated and the process repeated on the new residuals. \n",
    "\n",
    "In the original implemtation of this method, the individual trees would only be split once, and so they would have only 2 terminal nodes. With more recent implementations trees can be deeper, although often on a few terminal nodes is sufficient. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters of the Model\n",
    "\n",
    "I am using the <a href=\"http://docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science/gbm.html\"> H2O</a> GBM implementation. \n",
    "\n",
    "What follows is a list of parameters and notes about their applicability to the problem in hand:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| | |\n",
    "|---|---|---|\n",
    "|**Parameter** |**From the Docs** |**Notes**|\n",
    "| `ntrees` | Specify the number of trees to build | In general a small learning rate and a large number of trees is preferable. In practice we will estimate the optimal number of trees with a cross=-validated approach. As a rule of thumb the number of trees should not be less than 1000. |\n",
    "| `max_depth` | Specify the maximum tree depth| Deeper trees perform better on a training set as they can overfit the data. Greater depth also increases the computation time, particulalry for trees greter than depth 10. An optimal range of depths will be estimated using a gridsearch.|\n",
    "|`min_rows` | Specify the minimum number of observations for a leaf  | This option specifies the number of observations that must be in the leafs that result from a split if the split is to be allowed to happen. The default value is 10. It seems like there is no need to optimize this parameter.|\n",
    "|`nbins`| (Numerical/real/int only) Specify the number of bins for the histogram to build, then split at the best point | When a split in the data is being considered, a histogram is constructed of the feature and the best split is determined. The splits are made at the boundaries of the bins. Increasing the number of bins increased the specificity of the model (and can lead to overfitting). If we observe overfitting in our models we will reduce the number of bins from the default 20.|\n",
    "|`nbins_cats` | (Categorical/facor only) Specify the number of bins for the histogram to build, then split at the best point  | A small value for catgroical vairables with many levels introduces randomness to the split, where large values result in perfect splits and overfitting. If we observe overfitting in our models we will reduce the number of bins from the default 1024|\n",
    "| `learn_rate`|Specify the learning rate. | Lower rates are better but require more trees|\n",
    "|`learn_rate_anealing` | Specifies to reduce the `learn_rate` by this factor after every tree. |  Instead of using a learn rate of 0.01, we can try a learn rate of 0.05 with an anealing of 0.99. The result should be generated more quickly without much accuracy being sacrificed \n",
    "|`sample_rate_per_class` | Specifies that each tree in the ensemble should sample from the full training dataset using a per-class-specific sampling rate rather than a global sample factor | This is useful when working with unbalanced data sets like this one. It varies between 0 and 1, 1 improves training score, less than one improves test scores. I could not figure out how to correctly tune this parameter so it does not appear below.|\n",
    "| `col_sample_rate` | Specify the column sampling rate (y-axis) | Good general values for large datasets are around 0.7 to 0.8  |\n",
    "| `max_abs_leafnode_pred` | Reduces overfitting by limiting the maximum absolute value of a leaf node prediction. | |\n",
    "| `'min_split_improvement` | Specifies the minimum relative improvement in squared error reduction in order for a split to happen. | When properly tuned, this option can help reduce overfitting. Optimal values would be in the 1e-10...1e-3 range.|\n",
    "|`balance_classes` | Specify whether to oversample the minority classes to balance the class distribution. | This is useful when the response variable is highly imbalanced, as it is in this case. When used the model undersamples majority classes or oversamples minority classes. This option will be used in all models. |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#imports\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import h2o\n",
    "from h2o.estimators.gbm import H2OGradientBoostingEstimator\n",
    "from h2o.grid.grid_search import H2OGridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "  Java Version: java version \"1.7.0_151\"; OpenJDK Runtime Environment (amzn-2.6.11.0.74.amzn1-x86_64 u151-b00); OpenJDK 64-Bit Server VM (build 24.151-b00, mixed mode)\n",
      "  Starting server from /home/ec2-user/anaconda3/lib/python3.6/site-packages/h2o/backend/bin/h2o.jar\n",
      "  Ice root: /tmp/tmp3vpisxwn\n",
      "  JVM stdout: /tmp/tmp3vpisxwn/h2o_ec2_user_started_from_python.out\n",
      "  JVM stderr: /tmp/tmp3vpisxwn/h2o_ec2_user_started_from_python.err\n",
      "  Server is running at http://127.0.0.1:54321\n",
      "Connecting to H2O server at http://127.0.0.1:54321... successful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O cluster uptime:</td>\n",
       "<td>02 secs</td></tr>\n",
       "<tr><td>H2O cluster version:</td>\n",
       "<td>3.15.0.4050</td></tr>\n",
       "<tr><td>H2O cluster version age:</td>\n",
       "<td>1 day </td></tr>\n",
       "<tr><td>H2O cluster name:</td>\n",
       "<td>H2O_from_python_ec2_user_ibh5wr</td></tr>\n",
       "<tr><td>H2O cluster total nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O cluster free memory:</td>\n",
       "<td>26.52 Gb</td></tr>\n",
       "<tr><td>H2O cluster total cores:</td>\n",
       "<td>64</td></tr>\n",
       "<tr><td>H2O cluster allowed cores:</td>\n",
       "<td>64</td></tr>\n",
       "<tr><td>H2O cluster status:</td>\n",
       "<td>accepting new members, healthy</td></tr>\n",
       "<tr><td>H2O connection url:</td>\n",
       "<td>http://127.0.0.1:54321</td></tr>\n",
       "<tr><td>H2O connection proxy:</td>\n",
       "<td>None</td></tr>\n",
       "<tr><td>H2O internal security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>H2O API Extensions:</td>\n",
       "<td>AutoML, XGBoost, Algos, Core V3, Core V4</td></tr>\n",
       "<tr><td>Python version:</td>\n",
       "<td>3.6.2 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  ----------------------------------------\n",
       "H2O cluster uptime:         02 secs\n",
       "H2O cluster version:        3.15.0.4050\n",
       "H2O cluster version age:    1 day\n",
       "H2O cluster name:           H2O_from_python_ec2_user_ibh5wr\n",
       "H2O cluster total nodes:    1\n",
       "H2O cluster free memory:    26.52 Gb\n",
       "H2O cluster total cores:    64\n",
       "H2O cluster allowed cores:  64\n",
       "H2O cluster status:         accepting new members, healthy\n",
       "H2O connection url:         http://127.0.0.1:54321\n",
       "H2O connection proxy:\n",
       "H2O internal security:      False\n",
       "H2O API Extensions:         AutoML, XGBoost, Algos, Core V3, Core V4\n",
       "Python version:             3.6.2 final\n",
       "--------------------------  ----------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#initialize h2o cluster\n",
    "h2o.init(nthreads=-1, strict_version_check=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is being run on an AWS virtual Linux machine with 64 CPUs, as can be seen from the number of H2O clusers.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "train60 35818\n",
      "train80 47612\n",
      "valid 11794\n",
      "test 11769\n"
     ]
    }
   ],
   "source": [
    "#import the dataset\n",
    "df = pd.read_csv('train.csv')\n",
    "\n",
    "#split the Product_info2 variable\n",
    "df['product_Letter'] = df['Product_Info_2'].str.slice(0, 1)\\\n",
    "                       .astype('category')\\\n",
    "                       .cat.codes\n",
    "\n",
    "df['product_Number'] = df['Product_Info_2'].str.slice(1, 2)\\\n",
    "                       .astype(int)\n",
    "    \n",
    "df = df.drop('Product_Info_2', axis=1)\n",
    "\n",
    "#create a sum of the medical data\n",
    "df['health_sum'] = df.filter(regex='Medical_Key').sum(axis=1)\n",
    "\n",
    "#convert to H2OFrame\n",
    "h2oDF = h2o.H2OFrame(df)\n",
    "\n",
    "#convert factors to factor types\n",
    "factor_cols = ['Product_Info_1', 'Product_Info_3', 'Product_Info_5', 'Product_Info_6', \n",
    "               'Product_Info_7', 'Employment_Info_2', 'Employment_Info_3', \n",
    "               'Employment_Info_5', 'InsuredInfo_1', 'InsuredInfo_2', 'InsuredInfo_3', \n",
    "               'InsuredInfo_4', 'InsuredInfo_5', 'InsuredInfo_6', 'InsuredInfo_7', \n",
    "               'Insurance_History_1', 'Insurance_History_2', 'Insurance_History_3', \n",
    "               'Insurance_History_4', 'Insurance_History_7', 'Insurance_History_8', \n",
    "               'Insurance_History_9', 'Family_Hist_1', 'Medical_History_2', 'Medical_History_3',\n",
    "               'Medical_History_4', 'Medical_History_5', 'Medical_History_6', 'Medical_History_7', \n",
    "               'Medical_History_8', 'Medical_History_9', 'Medical_History_11', 'Medical_History_12', \n",
    "               'Medical_History_13', 'Medical_History_14', 'Medical_History_16', 'Medical_History_17', \n",
    "               'Medical_History_18', 'Medical_History_19', 'Medical_History_20', 'Medical_History_21', \n",
    "               'Medical_History_22', 'Medical_History_23', 'Medical_History_25', 'Medical_History_26', \n",
    "               'Medical_History_27', 'Medical_History_28', 'Medical_History_29', 'Medical_History_30', \n",
    "               'Medical_History_31', 'Medical_History_33', 'Medical_History_34', 'Medical_History_35', \n",
    "               'Medical_History_36', 'Medical_History_37', 'Medical_History_38', 'Medical_History_39', \n",
    "               'Medical_History_40', 'Medical_History_41', 'Response', 'product_Letter', \n",
    "               'product_Number']\n",
    "\n",
    "for col in factor_cols:\n",
    "    h2oDF[col] = h2oDF[col].asfactor()\n",
    "    \n",
    "# determine the response\n",
    "response = \"Response\"\n",
    "\n",
    "#determine the predictors\n",
    "predictors = h2oDF.columns\n",
    "del predictors[-4] #Response\n",
    "del predictors[0]  #ID\n",
    "\n",
    "#split the data into three pieces:\n",
    "\n",
    "#1. 60% Training data\n",
    "#2. 20% Validation data\n",
    "#3. 20% Test data\n",
    "\n",
    "seed = 20170929 #nunu's birthday\n",
    "train60, valid, test = h2oDF.split_frame(ratios = [0.6, 0.2], seed = seed)\n",
    "train80 = train60.rbind(valid)\n",
    "print('train60', len(train60))\n",
    "print('train80', len(train80))\n",
    "print('valid', len(valid))\n",
    "print('test', len(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I start by establishing baseline performance for the train set, by taking the default parameters for the GBM estimator. The only parameters that I add are the `distribution` (as this is a multinomial classification problem) and the `balance_classes` parameter as the response variable is highly imbalanced.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm Model Build progress: |███████████████████████████████████████████████| 100%\n",
      "--- 11.308806419372559 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "baseline = H2OGradientBoostingEstimator(distribution='multinomial', balance_classes=True)\n",
    "baseline.train(x=predictors, y=response, training_frame=train60)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ModelMetricsMultinomial: gbm\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.34184425893878667\n",
      "RMSE: 0.5846744897280766\n",
      "LogLoss: 1.0088513799079613\n",
      "Mean Per-Class Error: 0.3106870284628406\n",
      "Confusion Matrix: Row labels: Actual class; Column labels: Predicted class\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>1</b></td>\n",
       "<td><b>2</b></td>\n",
       "<td><b>3</b></td>\n",
       "<td><b>4</b></td>\n",
       "<td><b>5</b></td>\n",
       "<td><b>6</b></td>\n",
       "<td><b>7</b></td>\n",
       "<td><b>8</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>5900.0</td>\n",
       "<td>543.0</td>\n",
       "<td>90.0</td>\n",
       "<td>195.0</td>\n",
       "<td>591.0</td>\n",
       "<td>1291.0</td>\n",
       "<td>935.0</td>\n",
       "<td>2264.0</td>\n",
       "<td>0.5003811</td>\n",
       "<td>5,909 / 11,809</td></tr>\n",
       "<tr><td>282.0</td>\n",
       "<td>5720.0</td>\n",
       "<td>96.0</td>\n",
       "<td>175.0</td>\n",
       "<td>774.0</td>\n",
       "<td>1601.0</td>\n",
       "<td>896.0</td>\n",
       "<td>2250.0</td>\n",
       "<td>0.5150076</td>\n",
       "<td>6,074 / 11,794</td></tr>\n",
       "<tr><td>59.0</td>\n",
       "<td>117.0</td>\n",
       "<td>9593.0</td>\n",
       "<td>698.0</td>\n",
       "<td>229.0</td>\n",
       "<td>560.0</td>\n",
       "<td>174.0</td>\n",
       "<td>387.0</td>\n",
       "<td>0.1882034</td>\n",
       "<td>2,224 / 11,817</td></tr>\n",
       "<tr><td>55.0</td>\n",
       "<td>0.0</td>\n",
       "<td>40.0</td>\n",
       "<td>10135.0</td>\n",
       "<td>0.0</td>\n",
       "<td>339.0</td>\n",
       "<td>162.0</td>\n",
       "<td>1075.0</td>\n",
       "<td>0.1415382</td>\n",
       "<td>1,671 / 11,806</td></tr>\n",
       "<tr><td>106.0</td>\n",
       "<td>430.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>8086.0</td>\n",
       "<td>1403.0</td>\n",
       "<td>587.0</td>\n",
       "<td>1139.0</td>\n",
       "<td>0.3118883</td>\n",
       "<td>3,665 / 11,751</td></tr>\n",
       "<tr><td>206.0</td>\n",
       "<td>205.0</td>\n",
       "<td>3.0</td>\n",
       "<td>12.0</td>\n",
       "<td>351.0</td>\n",
       "<td>7690.0</td>\n",
       "<td>1213.0</td>\n",
       "<td>2176.0</td>\n",
       "<td>0.3513833</td>\n",
       "<td>4,166 / 11,856</td></tr>\n",
       "<tr><td>57.0</td>\n",
       "<td>27.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>47.0</td>\n",
       "<td>1183.0</td>\n",
       "<td>6818.0</td>\n",
       "<td>3646.0</td>\n",
       "<td>0.4211241</td>\n",
       "<td>4,960 / 11,778</td></tr>\n",
       "<tr><td>17.0</td>\n",
       "<td>8.0</td>\n",
       "<td>0.0</td>\n",
       "<td>4.0</td>\n",
       "<td>15.0</td>\n",
       "<td>266.0</td>\n",
       "<td>350.0</td>\n",
       "<td>11132.0</td>\n",
       "<td>0.0559701</td>\n",
       "<td>660 / 11,792</td></tr>\n",
       "<tr><td>6682.0</td>\n",
       "<td>7050.0</td>\n",
       "<td>9822.0</td>\n",
       "<td>11219.0</td>\n",
       "<td>10093.0</td>\n",
       "<td>14333.0</td>\n",
       "<td>11135.0</td>\n",
       "<td>24069.0</td>\n",
       "<td>0.3106787</td>\n",
       "<td>29,329 / 94,403</td></tr></table></div>"
      ],
      "text/plain": [
       "1     2     3     4      5      6      7      8      Error      Rate\n",
       "----  ----  ----  -----  -----  -----  -----  -----  ---------  ---------------\n",
       "5900  543   90    195    591    1291   935    2264   0.500381   5,909 / 11,809\n",
       "282   5720  96    175    774    1601   896    2250   0.515008   6,074 / 11,794\n",
       "59    117   9593  698    229    560    174    387    0.188203   2,224 / 11,817\n",
       "55    0     40    10135  0      339    162    1075   0.141538   1,671 / 11,806\n",
       "106   430   0     0      8086   1403   587    1139   0.311888   3,665 / 11,751\n",
       "206   205   3     12     351    7690   1213   2176   0.351383   4,166 / 11,856\n",
       "57    27    0     0      47     1183   6818   3646   0.421124   4,960 / 11,778\n",
       "17    8     0     4      15     266    350    11132  0.0559701  660 / 11,792\n",
       "6682  7050  9822  11219  10093  14333  11135  24069  0.310679   29,329 / 94,403"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-8 Hit Ratios: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>k</b></td>\n",
       "<td><b>hit_ratio</b></td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>0.6893213</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.835768</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.9031599</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.9468026</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.9714735</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.988867</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.9987713</td></tr>\n",
       "<tr><td>8</td>\n",
       "<td>1.0000001</td></tr></table></div>"
      ],
      "text/plain": [
       "k    hit_ratio\n",
       "---  -----------\n",
       "1    0.689321\n",
       "2    0.835768\n",
       "3    0.90316\n",
       "4    0.946803\n",
       "5    0.971473\n",
       "6    0.988867\n",
       "7    0.998771\n",
       "8    1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline.model_performance()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance is good even with with default model. However the extent of overfitting is not known, and so we perform the same exercise with 5 fold cross validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm Model Build progress: |███████████████████████████████████████████████| 100%\n",
      "--- 100.31310510635376 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "CVbaseline = H2OGradientBoostingEstimator(distribution='multinomial', balance_classes=True, \n",
    "                                          nfolds=5, seed=seed)\n",
    "CVbaseline.train(x=predictors, y=response, training_frame=train80)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train mean per class error 0.33224066114924866\n"
     ]
    }
   ],
   "source": [
    "print('Train mean per class error', CVbaseline.mean_per_class_error(train=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>sd</th>\n",
       "      <th>cv_1_valid</th>\n",
       "      <th>cv_2_valid</th>\n",
       "      <th>cv_3_valid</th>\n",
       "      <th>cv_4_valid</th>\n",
       "      <th>cv_5_valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.55355775</td>\n",
       "      <td>0.001520318</td>\n",
       "      <td>0.5506971</td>\n",
       "      <td>0.5546034</td>\n",
       "      <td>0.5556143</td>\n",
       "      <td>0.55124855</td>\n",
       "      <td>0.5556254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>err</td>\n",
       "      <td>0.44644225</td>\n",
       "      <td>0.001520318</td>\n",
       "      <td>0.4493029</td>\n",
       "      <td>0.4453966</td>\n",
       "      <td>0.4443857</td>\n",
       "      <td>0.44875145</td>\n",
       "      <td>0.44437462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>err_count</td>\n",
       "      <td>4251.2</td>\n",
       "      <td>21.09692</td>\n",
       "      <td>4254.0</td>\n",
       "      <td>4262.0</td>\n",
       "      <td>4203.0</td>\n",
       "      <td>4295.0</td>\n",
       "      <td>4242.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>logloss</td>\n",
       "      <td>1.2787966</td>\n",
       "      <td>0.0049447035</td>\n",
       "      <td>1.2873873</td>\n",
       "      <td>1.273314</td>\n",
       "      <td>1.2727906</td>\n",
       "      <td>1.2873297</td>\n",
       "      <td>1.2731613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max_per_class_error</td>\n",
       "      <td>0.8190659</td>\n",
       "      <td>0.0062207775</td>\n",
       "      <td>0.8301887</td>\n",
       "      <td>0.8094241</td>\n",
       "      <td>0.8263959</td>\n",
       "      <td>0.8208955</td>\n",
       "      <td>0.80842525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mean_per_class_accuracy</td>\n",
       "      <td>0.46130127</td>\n",
       "      <td>0.0033562302</td>\n",
       "      <td>0.45728013</td>\n",
       "      <td>0.46135736</td>\n",
       "      <td>0.45514297</td>\n",
       "      <td>0.46827403</td>\n",
       "      <td>0.46445188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>mean_per_class_error</td>\n",
       "      <td>0.53869873</td>\n",
       "      <td>0.0033562302</td>\n",
       "      <td>0.54271984</td>\n",
       "      <td>0.53864264</td>\n",
       "      <td>0.544857</td>\n",
       "      <td>0.531726</td>\n",
       "      <td>0.5355481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mse</td>\n",
       "      <td>0.4301344</td>\n",
       "      <td>7.164079E-4</td>\n",
       "      <td>0.4315152</td>\n",
       "      <td>0.4298728</td>\n",
       "      <td>0.42853418</td>\n",
       "      <td>0.4308653</td>\n",
       "      <td>0.42988443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>r2</td>\n",
       "      <td>0.92853343</td>\n",
       "      <td>3.9531346E-4</td>\n",
       "      <td>0.9289005</td>\n",
       "      <td>0.92764693</td>\n",
       "      <td>0.9281074</td>\n",
       "      <td>0.9289242</td>\n",
       "      <td>0.9290883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>rmse</td>\n",
       "      <td>0.6558458</td>\n",
       "      <td>5.4623996E-4</td>\n",
       "      <td>0.65689814</td>\n",
       "      <td>0.65564686</td>\n",
       "      <td>0.65462524</td>\n",
       "      <td>0.6564033</td>\n",
       "      <td>0.65565574</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  mean            sd  cv_1_valid  cv_2_valid  \\\n",
       "0                 accuracy  0.55355775   0.001520318   0.5506971   0.5546034   \n",
       "1                      err  0.44644225   0.001520318   0.4493029   0.4453966   \n",
       "2                err_count      4251.2      21.09692      4254.0      4262.0   \n",
       "3                  logloss   1.2787966  0.0049447035   1.2873873    1.273314   \n",
       "4      max_per_class_error   0.8190659  0.0062207775   0.8301887   0.8094241   \n",
       "5  mean_per_class_accuracy  0.46130127  0.0033562302  0.45728013  0.46135736   \n",
       "6     mean_per_class_error  0.53869873  0.0033562302  0.54271984  0.53864264   \n",
       "7                      mse   0.4301344   7.164079E-4   0.4315152   0.4298728   \n",
       "8                       r2  0.92853343  3.9531346E-4   0.9289005  0.92764693   \n",
       "9                     rmse   0.6558458  5.4623996E-4  0.65689814  0.65564686   \n",
       "\n",
       "   cv_3_valid  cv_4_valid  cv_5_valid  \n",
       "0   0.5556143  0.55124855   0.5556254  \n",
       "1   0.4443857  0.44875145  0.44437462  \n",
       "2      4203.0      4295.0      4242.0  \n",
       "3   1.2727906   1.2873297   1.2731613  \n",
       "4   0.8263959   0.8208955  0.80842525  \n",
       "5  0.45514297  0.46827403  0.46445188  \n",
       "6    0.544857    0.531726   0.5355481  \n",
       "7  0.42853418   0.4308653  0.42988443  \n",
       "8   0.9281074   0.9289242   0.9290883  \n",
       "9  0.65462524   0.6564033  0.65565574  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cross vlaidation metrics\n",
    "CVbaseline.cross_validation_metrics_summary().as_data_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#training data model performance\n",
    "CVbaseline.model_performance(xval=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ModelMetricsMultinomial: gbm\n",
      "** Reported on cross-validation data. **\n",
      "\n",
      "MSE: 0.4301353274612132\n",
      "RMSE: 0.6558470305347225\n",
      "LogLoss: 1.278795393015315\n",
      "Mean Per-Class Error: 0.5386129410708305\n",
      "Confusion Matrix: Row labels: Actual class; Column labels: Predicted class\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>1</b></td>\n",
       "<td><b>2</b></td>\n",
       "<td><b>3</b></td>\n",
       "<td><b>4</b></td>\n",
       "<td><b>5</b></td>\n",
       "<td><b>6</b></td>\n",
       "<td><b>7</b></td>\n",
       "<td><b>8</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>895.0</td>\n",
       "<td>674.0</td>\n",
       "<td>94.0</td>\n",
       "<td>136.0</td>\n",
       "<td>449.0</td>\n",
       "<td>948.0</td>\n",
       "<td>590.0</td>\n",
       "<td>1163.0</td>\n",
       "<td>0.8191554</td>\n",
       "<td>4,054 / 4,949</td></tr>\n",
       "<tr><td>531.0</td>\n",
       "<td>1144.0</td>\n",
       "<td>84.0</td>\n",
       "<td>111.0</td>\n",
       "<td>650.0</td>\n",
       "<td>1022.0</td>\n",
       "<td>526.0</td>\n",
       "<td>1179.0</td>\n",
       "<td>0.7819706</td>\n",
       "<td>4,103 / 5,247</td></tr>\n",
       "<tr><td>122.0</td>\n",
       "<td>57.0</td>\n",
       "<td>284.0</td>\n",
       "<td>191.0</td>\n",
       "<td>30.0</td>\n",
       "<td>62.0</td>\n",
       "<td>13.0</td>\n",
       "<td>38.0</td>\n",
       "<td>0.6436637</td>\n",
       "<td>513 / 797</td></tr>\n",
       "<tr><td>76.0</td>\n",
       "<td>16.0</td>\n",
       "<td>79.0</td>\n",
       "<td>761.0</td>\n",
       "<td>2.0</td>\n",
       "<td>79.0</td>\n",
       "<td>24.0</td>\n",
       "<td>133.0</td>\n",
       "<td>0.3495726</td>\n",
       "<td>409 / 1,170</td></tr>\n",
       "<tr><td>171.0</td>\n",
       "<td>442.0</td>\n",
       "<td>2.0</td>\n",
       "<td>0.0</td>\n",
       "<td>2138.0</td>\n",
       "<td>860.0</td>\n",
       "<td>247.0</td>\n",
       "<td>504.0</td>\n",
       "<td>0.5100825</td>\n",
       "<td>2,226 / 4,364</td></tr>\n",
       "<tr><td>330.0</td>\n",
       "<td>390.0</td>\n",
       "<td>3.0</td>\n",
       "<td>17.0</td>\n",
       "<td>445.0</td>\n",
       "<td>4473.0</td>\n",
       "<td>1221.0</td>\n",
       "<td>2163.0</td>\n",
       "<td>0.5053086</td>\n",
       "<td>4,569 / 9,042</td></tr>\n",
       "<tr><td>127.0</td>\n",
       "<td>100.0</td>\n",
       "<td>0.0</td>\n",
       "<td>2.0</td>\n",
       "<td>51.0</td>\n",
       "<td>1159.0</td>\n",
       "<td>2555.0</td>\n",
       "<td>2432.0</td>\n",
       "<td>0.6023965</td>\n",
       "<td>3,871 / 6,426</td></tr>\n",
       "<tr><td>60.0</td>\n",
       "<td>54.0</td>\n",
       "<td>0.0</td>\n",
       "<td>11.0</td>\n",
       "<td>27.0</td>\n",
       "<td>688.0</td>\n",
       "<td>671.0</td>\n",
       "<td>14106.0</td>\n",
       "<td>0.0967535</td>\n",
       "<td>1,511 / 15,617</td></tr>\n",
       "<tr><td>2312.0</td>\n",
       "<td>2877.0</td>\n",
       "<td>546.0</td>\n",
       "<td>1229.0</td>\n",
       "<td>3792.0</td>\n",
       "<td>9291.0</td>\n",
       "<td>5847.0</td>\n",
       "<td>21718.0</td>\n",
       "<td>0.4464421</td>\n",
       "<td>21,256 / 47,612</td></tr></table></div>"
      ],
      "text/plain": [
       "1     2     3    4     5     6     7     8      Error      Rate\n",
       "----  ----  ---  ----  ----  ----  ----  -----  ---------  ---------------\n",
       "895   674   94   136   449   948   590   1163   0.819155   4,054 / 4,949\n",
       "531   1144  84   111   650   1022  526   1179   0.781971   4,103 / 5,247\n",
       "122   57    284  191   30    62    13    38     0.643664   513 / 797\n",
       "76    16    79   761   2     79    24    133    0.349573   409 / 1,170\n",
       "171   442   2    0     2138  860   247   504    0.510082   2,226 / 4,364\n",
       "330   390   3    17    445   4473  1221  2163   0.505309   4,569 / 9,042\n",
       "127   100   0    2     51    1159  2555  2432   0.602397   3,871 / 6,426\n",
       "60    54    0    11    27    688   671   14106  0.0967535  1,511 / 15,617\n",
       "2312  2877  546  1229  3792  9291  5847  21718  0.446442   21,256 / 47,612"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-8 Hit Ratios: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>k</b></td>\n",
       "<td><b>hit_ratio</b></td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>0.5535579</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.7377132</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.851088</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.9222045</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.9652818</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.9902335</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.9962404</td></tr>\n",
       "<tr><td>8</td>\n",
       "<td>1.0</td></tr></table></div>"
      ],
      "text/plain": [
       "k    hit_ratio\n",
       "---  -----------\n",
       "1    0.553558\n",
       "2    0.737713\n",
       "3    0.851088\n",
       "4    0.922204\n",
       "5    0.965282\n",
       "6    0.990234\n",
       "7    0.99624\n",
       "8    1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cross validation model performance\n",
    "CVbaseline.model_performance(xval=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a fairly significant distance between the mean_per_class_error of the training set and that of the validation set. To some extent this is expected, but... The mean squared errors are more stable between the train and validation sets. This is encouraging. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning  `learn_rate` and `max_depth`\n",
    "\n",
    "Most parameters will be estimated using a multi hyper-parameter search. However, for `learn_rate` and `max_depth` we will run them individually. This is because these parameters greatly affect the speed that convergance takes place, and therefore narrowing the search field is preferable. This is expecially true for the max_depth. Depths greater than 10 can massively slow down performance. \n",
    "\n",
    "We will use this exercise to understand how many trees should be specified for the `ntrees` parameter. The standard setting for `ntrees` is 1000. We can observe how many trees are actually built given the other parameters and then set the ntrees more specifically in the larger tuning exercise. \n",
    "\n",
    "We start by perfroming a grid search for the `max_depth` parameter. The values to be searched are between 1 and 30, at intervals of 2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm Grid Build progress: |████████████████████████████████████████████████| 100%\n",
      "--- 810.5275394916534 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "hyper_params = {'max_depth' : list(range(1, 30, 2))}\n",
    "\n",
    "depthModel = H2OGradientBoostingEstimator(\n",
    "    distribution='multinomial',\n",
    "    ntrees = 1000, #a standard value of ntrees\n",
    "    learn_rate=0.05, #a fairly standard value of learn_rate\n",
    "    learn_rate_annealing=0.99,\n",
    "    sample_rate = 0.8, #a fairly standard value for a large data set\n",
    "    col_sample_rate = 0.8, #a fairly standard value for a large data set\n",
    "    seed=seed,\n",
    "    score_tree_interval = 4,\n",
    "    stopping_rounds = 5,\n",
    "    stopping_metric = \"mean_per_class_error\",\n",
    "    stopping_tolerance = 1e-3)\n",
    "\n",
    "depthGrid = H2OGridSearch(depthModel, hyper_params)\n",
    "\n",
    "depthGrid.train(x=predictors,\n",
    "                y=response,\n",
    "                training_frame = train60,\n",
    "                validation_frame = valid)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     max_depth                                                      model_ids  \\\n",
      "0            3   Grid_GBM_py_65_sid_8734_model_python_1507061735713_5_model_1   \n",
      "1            5   Grid_GBM_py_65_sid_8734_model_python_1507061735713_5_model_2   \n",
      "2           17   Grid_GBM_py_65_sid_8734_model_python_1507061735713_5_model_8   \n",
      "3           19   Grid_GBM_py_65_sid_8734_model_python_1507061735713_5_model_9   \n",
      "4            7   Grid_GBM_py_65_sid_8734_model_python_1507061735713_5_model_3   \n",
      "5           23  Grid_GBM_py_65_sid_8734_model_python_1507061735713_5_model_11   \n",
      "6           21  Grid_GBM_py_65_sid_8734_model_python_1507061735713_5_model_10   \n",
      "7           13   Grid_GBM_py_65_sid_8734_model_python_1507061735713_5_model_6   \n",
      "8           27  Grid_GBM_py_65_sid_8734_model_python_1507061735713_5_model_13   \n",
      "9           29  Grid_GBM_py_65_sid_8734_model_python_1507061735713_5_model_14   \n",
      "10          25  Grid_GBM_py_65_sid_8734_model_python_1507061735713_5_model_12   \n",
      "11          15   Grid_GBM_py_65_sid_8734_model_python_1507061735713_5_model_7   \n",
      "12           9   Grid_GBM_py_65_sid_8734_model_python_1507061735713_5_model_4   \n",
      "13          11   Grid_GBM_py_65_sid_8734_model_python_1507061735713_5_model_5   \n",
      "14           1   Grid_GBM_py_65_sid_8734_model_python_1507061735713_5_model_0   \n",
      "\n",
      "   mean_per_class_error  \n",
      "0    0.5326005301577738  \n",
      "1    0.5348217821483695  \n",
      "2    0.5366781932755325  \n",
      "3    0.5377181317006009  \n",
      "4    0.5378934076518931  \n",
      "5     0.538572197015772  \n",
      "6    0.5385788885166494  \n",
      "7    0.5388312165394933  \n",
      "8    0.5398920003211761  \n",
      "9    0.5400870414601759  \n",
      "10   0.5404486712912197  \n",
      "11   0.5405640270944835  \n",
      "12   0.5414215918344129  \n",
      "13   0.5415147615441954  \n",
      "14   0.5729594935622978  \n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_depth_grid = depthGrid.get_grid(sort_by='mean_per_class_error')\n",
    "sorted_depth_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0\n",
      "valid MPCE 0.5326005301577738\n",
      "train MPCE 0.46508718616269923\n",
      "Model 1\n",
      "valid MPCE 0.5348217821483695\n",
      "train MPCE 0.39472570578367006\n",
      "Model 2\n",
      "valid MPCE 0.5366781932755325\n",
      "train MPCE 0.08340849485757895\n",
      "Model 3\n",
      "valid MPCE 0.5377181317006009\n",
      "train MPCE 0.029438585992860297\n",
      "Model 4\n",
      "valid MPCE 0.5378934076518931\n",
      "train MPCE 0.3193535729461138\n"
     ]
    }
   ],
   "source": [
    "for x in range(5):\n",
    "    print(\"Model {}\".format(x))\n",
    "    print(\"valid MPCE\", sorted_depth_grid[x].mean_per_class_error(valid=True))\n",
    "    print(\"train MPCE\", sorted_depth_grid[x].mean_per_class_error(train=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of trees 48.0\n",
      "number of trees 48.0\n",
      "number of trees 48.0\n",
      "number of trees 68.0\n",
      "number of trees 72.0\n"
     ]
    }
   ],
   "source": [
    "for model in list(depthGrid.mean_per_class_error().keys())[:5]:\n",
    "    print(\"number of trees\", (depthGrid.scoring_history()[model])['number_of_trees'].iloc[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sweet spot for the `max_depth` is between 3 and 19. However, it is worth noting that tuning this parameter has not brought significant gains to the validation set mean_per_class_error, and seems to have increased overfitting in some of the five best performing models. \n",
    "\n",
    "Next we tune the `learn_rate`. In general the learn rate should be low. The learn rate captures how correct observations are weighted after each tree is built. A small learn late should help with overfitting. Note that standard learn rates are 0.05 and 0.01. However, in testing I found that higher learn rates were performing better on this data (not sure why) and as such I am searching a space from 0.005 to 0.6 which is a much larger space than would typically be considered. \n",
    "\n",
    "I include the `learn_rate_annealing` parameter as this helps the tree to converge by lowering the learning rate for each tree (thereby increasing the chances of early stopping)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm Grid Build progress: |████████████████████████████████████████████████| 100%\n",
      "--- 2680.8130984306335 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "hyper_params2 = {'learn_rate' : [x/1000 for x in range(5, 601, 10)]}\n",
    "\n",
    "learnModel = H2OGradientBoostingEstimator(\n",
    "    distribution='multinomial',\n",
    "    learn_rate_annealing = 0.99,\n",
    "    max_depth = 15,\n",
    "    ntrees=1000,\n",
    "    sample_rate = 0.8,\n",
    "    col_sample_rate = 0.8,\n",
    "    seed=seed,\n",
    "    score_tree_interval = 4,\n",
    "    stopping_rounds = 5,\n",
    "    stopping_metric = \"mean_per_class_error\",\n",
    "    stopping_tolerance = 1e-3)\n",
    "\n",
    "learnGrid = H2OGridSearch(learnModel, hyper_params2)\n",
    "\n",
    "learnGrid.train(x=predictors,\n",
    "                y=response,\n",
    "                training_frame = train60,\n",
    "                validation_frame = valid)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     learn_rate  \\\n",
      "0         0.035   \n",
      "1         0.025   \n",
      "2         0.005   \n",
      "3         0.015   \n",
      "4         0.045   \n",
      "5         0.055   \n",
      "6         0.095   \n",
      "7         0.105   \n",
      "8         0.275   \n",
      "9         0.075   \n",
      "10        0.205   \n",
      "11        0.085   \n",
      "12        0.145   \n",
      "13        0.255   \n",
      "14        0.325   \n",
      "15        0.065   \n",
      "16        0.235   \n",
      "17        0.225   \n",
      "18        0.125   \n",
      "19        0.115   \n",
      "20        0.195   \n",
      "21        0.165   \n",
      "22        0.185   \n",
      "23        0.175   \n",
      "24        0.155   \n",
      "25        0.285   \n",
      "26        0.215   \n",
      "27        0.335   \n",
      "28        0.245   \n",
      "29        0.305   \n",
      "30        0.135   \n",
      "31        0.365   \n",
      "32        0.355   \n",
      "33        0.345   \n",
      "34        0.445   \n",
      "35        0.315   \n",
      "36        0.265   \n",
      "37        0.425   \n",
      "38        0.295   \n",
      "39        0.375   \n",
      "40        0.405   \n",
      "41        0.415   \n",
      "42        0.465   \n",
      "43        0.435   \n",
      "44        0.385   \n",
      "45        0.595   \n",
      "46        0.475   \n",
      "47        0.505   \n",
      "48        0.455   \n",
      "49        0.495   \n",
      "50        0.515   \n",
      "51        0.545   \n",
      "52        0.395   \n",
      "53        0.555   \n",
      "54        0.535   \n",
      "55        0.565   \n",
      "56        0.575   \n",
      "57        0.485   \n",
      "58        0.525   \n",
      "59        0.585   \n",
      "\n",
      "                                                        model_ids  \\\n",
      "0    Grid_GBM_py_65_sid_8734_model_python_1507061735713_6_model_3   \n",
      "1    Grid_GBM_py_65_sid_8734_model_python_1507061735713_6_model_2   \n",
      "2    Grid_GBM_py_65_sid_8734_model_python_1507061735713_6_model_0   \n",
      "3    Grid_GBM_py_65_sid_8734_model_python_1507061735713_6_model_1   \n",
      "4    Grid_GBM_py_65_sid_8734_model_python_1507061735713_6_model_4   \n",
      "5    Grid_GBM_py_65_sid_8734_model_python_1507061735713_6_model_5   \n",
      "6    Grid_GBM_py_65_sid_8734_model_python_1507061735713_6_model_9   \n",
      "7   Grid_GBM_py_65_sid_8734_model_python_1507061735713_6_model_10   \n",
      "8   Grid_GBM_py_65_sid_8734_model_python_1507061735713_6_model_27   \n",
      "9    Grid_GBM_py_65_sid_8734_model_python_1507061735713_6_model_7   \n",
      "10  Grid_GBM_py_65_sid_8734_model_python_1507061735713_6_model_20   \n",
      "11   Grid_GBM_py_65_sid_8734_model_python_1507061735713_6_model_8   \n",
      "12  Grid_GBM_py_65_sid_8734_model_python_1507061735713_6_model_14   \n",
      "13  Grid_GBM_py_65_sid_8734_model_python_1507061735713_6_model_25   \n",
      "14  Grid_GBM_py_65_sid_8734_model_python_1507061735713_6_model_32   \n",
      "15   Grid_GBM_py_65_sid_8734_model_python_1507061735713_6_model_6   \n",
      "16  Grid_GBM_py_65_sid_8734_model_python_1507061735713_6_model_23   \n",
      "17  Grid_GBM_py_65_sid_8734_model_python_1507061735713_6_model_22   \n",
      "18  Grid_GBM_py_65_sid_8734_model_python_1507061735713_6_model_12   \n",
      "19  Grid_GBM_py_65_sid_8734_model_python_1507061735713_6_model_11   \n",
      "20  Grid_GBM_py_65_sid_8734_model_python_1507061735713_6_model_19   \n",
      "21  Grid_GBM_py_65_sid_8734_model_python_1507061735713_6_model_16   \n",
      "22  Grid_GBM_py_65_sid_8734_model_python_1507061735713_6_model_18   \n",
      "23  Grid_GBM_py_65_sid_8734_model_python_1507061735713_6_model_17   \n",
      "24  Grid_GBM_py_65_sid_8734_model_python_1507061735713_6_model_15   \n",
      "25  Grid_GBM_py_65_sid_8734_model_python_1507061735713_6_model_28   \n",
      "26  Grid_GBM_py_65_sid_8734_model_python_1507061735713_6_model_21   \n",
      "27  Grid_GBM_py_65_sid_8734_model_python_1507061735713_6_model_33   \n",
      "28  Grid_GBM_py_65_sid_8734_model_python_1507061735713_6_model_24   \n",
      "29  Grid_GBM_py_65_sid_8734_model_python_1507061735713_6_model_30   \n",
      "30  Grid_GBM_py_65_sid_8734_model_python_1507061735713_6_model_13   \n",
      "31  Grid_GBM_py_65_sid_8734_model_python_1507061735713_6_model_36   \n",
      "32  Grid_GBM_py_65_sid_8734_model_python_1507061735713_6_model_35   \n",
      "33  Grid_GBM_py_65_sid_8734_model_python_1507061735713_6_model_34   \n",
      "34  Grid_GBM_py_65_sid_8734_model_python_1507061735713_6_model_44   \n",
      "35  Grid_GBM_py_65_sid_8734_model_python_1507061735713_6_model_31   \n",
      "36  Grid_GBM_py_65_sid_8734_model_python_1507061735713_6_model_26   \n",
      "37  Grid_GBM_py_65_sid_8734_model_python_1507061735713_6_model_42   \n",
      "38  Grid_GBM_py_65_sid_8734_model_python_1507061735713_6_model_29   \n",
      "39  Grid_GBM_py_65_sid_8734_model_python_1507061735713_6_model_37   \n",
      "40  Grid_GBM_py_65_sid_8734_model_python_1507061735713_6_model_40   \n",
      "41  Grid_GBM_py_65_sid_8734_model_python_1507061735713_6_model_41   \n",
      "42  Grid_GBM_py_65_sid_8734_model_python_1507061735713_6_model_46   \n",
      "43  Grid_GBM_py_65_sid_8734_model_python_1507061735713_6_model_43   \n",
      "44  Grid_GBM_py_65_sid_8734_model_python_1507061735713_6_model_38   \n",
      "45  Grid_GBM_py_65_sid_8734_model_python_1507061735713_6_model_59   \n",
      "46  Grid_GBM_py_65_sid_8734_model_python_1507061735713_6_model_47   \n",
      "47  Grid_GBM_py_65_sid_8734_model_python_1507061735713_6_model_50   \n",
      "48  Grid_GBM_py_65_sid_8734_model_python_1507061735713_6_model_45   \n",
      "49  Grid_GBM_py_65_sid_8734_model_python_1507061735713_6_model_49   \n",
      "50  Grid_GBM_py_65_sid_8734_model_python_1507061735713_6_model_51   \n",
      "51  Grid_GBM_py_65_sid_8734_model_python_1507061735713_6_model_54   \n",
      "52  Grid_GBM_py_65_sid_8734_model_python_1507061735713_6_model_39   \n",
      "53  Grid_GBM_py_65_sid_8734_model_python_1507061735713_6_model_55   \n",
      "54  Grid_GBM_py_65_sid_8734_model_python_1507061735713_6_model_53   \n",
      "55  Grid_GBM_py_65_sid_8734_model_python_1507061735713_6_model_56   \n",
      "56  Grid_GBM_py_65_sid_8734_model_python_1507061735713_6_model_57   \n",
      "57  Grid_GBM_py_65_sid_8734_model_python_1507061735713_6_model_48   \n",
      "58  Grid_GBM_py_65_sid_8734_model_python_1507061735713_6_model_52   \n",
      "59  Grid_GBM_py_65_sid_8734_model_python_1507061735713_6_model_58   \n",
      "\n",
      "   mean_per_class_error  \n",
      "0    0.5339439192825468  \n",
      "1    0.5366625025848393  \n",
      "2    0.5373379388786985  \n",
      "3    0.5374451071104057  \n",
      "4    0.5380081720825463  \n",
      "5     0.539830706241102  \n",
      "6    0.5399081190143721  \n",
      "7    0.5400673888216896  \n",
      "8    0.5417980863665152  \n",
      "9     0.542457257813432  \n",
      "10    0.542657514820486  \n",
      "11   0.5433353019419687  \n",
      "12   0.5433498517018704  \n",
      "13   0.5438684725056806  \n",
      "14   0.5454580387349455  \n",
      "15    0.545593298503872  \n",
      "16   0.5457082162281315  \n",
      "17    0.546659417935427  \n",
      "18   0.5467520499874406  \n",
      "19   0.5486684290980522  \n",
      "20   0.5489346636267937  \n",
      "21    0.549604869718858  \n",
      "22    0.550028317295183  \n",
      "23   0.5505456356386432  \n",
      "24    0.551256594699325  \n",
      "25   0.5515845713405385  \n",
      "26   0.5516335253575738  \n",
      "27   0.5526180066540409  \n",
      "28   0.5527035928825365  \n",
      "29   0.5529481804756926  \n",
      "30    0.553173889816679  \n",
      "31   0.5540173162782386  \n",
      "32   0.5543181776378693  \n",
      "33   0.5571826701758511  \n",
      "34    0.558717112589487  \n",
      "35    0.559704655564223  \n",
      "36   0.5601726984382557  \n",
      "37   0.5629351198933047  \n",
      "38   0.5655520724058458  \n",
      "39   0.6023527599514947  \n",
      "40   0.6076476438006125  \n",
      "41   0.6206659493342538  \n",
      "42   0.6220735222473306  \n",
      "43   0.6298913109811257  \n",
      "44   0.6355437058076826  \n",
      "45   0.6390789367706234  \n",
      "46   0.6411551808346965  \n",
      "47   0.6427457482474693  \n",
      "48   0.6439731526535775  \n",
      "49   0.6443464943501345  \n",
      "50   0.6448407688665422  \n",
      "51   0.6450517554564493  \n",
      "52   0.6492085788367339  \n",
      "53   0.6496271160924465  \n",
      "54   0.6510220387455466  \n",
      "55   0.6521133465807128  \n",
      "56   0.6538521979846308  \n",
      "57   0.6578968886438468  \n",
      "58   0.6630434833630254  \n",
      "59   0.6653280255790633  \n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_learn_grid = learnGrid.get_grid(sort_by='mean_per_class_error')\n",
    "sorted_learn_grid "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0\n",
      "valid MPCE 0.5339439192825468\n",
      "train MPCE 0.11534431492531119\n",
      "Model 1\n",
      "valid MPCE 0.5366625025848393\n",
      "train MPCE 0.1441639214072638\n",
      "Model 2\n",
      "valid MPCE 0.5373379388786985\n",
      "train MPCE 0.21926398067242622\n",
      "Model 3\n",
      "valid MPCE 0.5374451071104057\n",
      "train MPCE 0.19240577794490843\n",
      "Model 4\n",
      "valid MPCE 0.5380081720825463\n",
      "train MPCE 0.10411344307316037\n"
     ]
    }
   ],
   "source": [
    "for x in range(5):\n",
    "    print(\"Model {}\".format(x))\n",
    "    print(\"valid MPCE\", sorted_learn_grid[x].mean_per_class_error(valid=True))\n",
    "    print(\"train MPCE\", sorted_learn_grid[x].mean_per_class_error(train=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sweet spot for the learn_rate appears to be between 0.005 and 0.05. Again, these small learn rates do not appear to be doing anything for the overfitting problem as the difference between train and valid scores has been increased. \n",
    "\n",
    "For the remaining tuning parameters (including those that I hope will prevent overfitting), I will run the program in an ipython kernel in AWS to take advantage of the persistency offered by using the amazon servers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#learnGrid.get_grid(sort_by='mean_per_class_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#wlearnGrid.scoring_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "################\n",
    "##THE FOLLOWING CODE WAS RUN IN AN IPYTHON TERMINAL TO PREVENT DATA LOSS IN THE EVENT OF SSH FAILURE\n",
    "#\n",
    "#\n",
    "#learn_range = [0.005, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06]\n",
    "#start_time = time.time()\n",
    "#hyper_params = {'learn_rate' : learn_range,\n",
    "#                'max_depth' : list(range(3, 19, 2)),\n",
    "#                'col_sample_rate' : [x/100 for x in range(70, 81, 5)],\n",
    "#                'col_sample_rate_per_tree': [x/100. for x in range(20,101)],\n",
    "#                'sample_rate' : [x/100 for x in range(70, 86, 5)],\n",
    "#                'nbins' : [2**x for x in range(4,11)],\n",
    "#                'nbins_cats': [2**x for x in range(4,11)],\n",
    "#                'min_split_improvement' : [1/x for x in [1000, 10000, 100000, 1000000, 10000000, \n",
    "#                                                         10000000, 1000000000, 10000000000]] }\n",
    "#tuneModel = H2OGradientBoostingEstimator(distribution = 'multinomial',\n",
    "#                                         balance_classes=True,\n",
    "#                                         learn_rate_annealing = 0.99,\n",
    "#                                         ntrees = 500,\n",
    "#                                         stopping_rounds = 3,\n",
    "#                                         stopping_metric = \"mean_per_class_error\",\n",
    "#                                         stopping_tolerance = 1e-3)\n",
    "#\n",
    "#search_params = {'strategy': \"RandomDiscrete\",\n",
    "#                 'seed' : 20170929,\n",
    "#                 'stopping_rounds' : 5,\n",
    "#                 'stopping_metric' : \"mean_per_class_error\",\n",
    "#                 'stopping_tolerance': 1e-3,\n",
    "#                 'max_models' : 1000,\n",
    "#                 'max_runtime_secs' : 7200}\n",
    "#\n",
    "#tuneModelGrid = H2OGridSearch(tuneModel, hyper_params=hyper_params, \n",
    "#                              search_criteria=search_params)\n",
    "#\n",
    "#tuneModelGrid.train(x=predictors,\n",
    "#                    y=response,\n",
    "#                    training_frame = train60,\n",
    "#                    validation_frame = valid)\n",
    "#\n",
    "#print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "##save some model outputs\n",
    "#pickle.dump(tuneModelGrid.scoring_history(), open(\"tuneGridScoreHistory.pkl\", \"wb\"))\n",
    "#sorted_grid = sorted(tuneModelGrid.mean_per_class_error(valid=True).items(),key=lambda x: x[1])\n",
    "#pickle.dump(sorted_grid, open(\"meanClassError.pkl\", \"wb\"))\n",
    "##asave top 10 performing models\n",
    "#for model in sorted_grid[:10]:\n",
    "#    m = h2o.get_model(model[0])\n",
    "#    model_path = h2o.save_model(model=m, path=\"\", force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/finalGaProject\n"
     ]
    }
   ],
   "source": [
    "cd ~/finalGaProject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Grid_GBM_py_65_sid_be2c_model_python_1507067122023_1_model_29',\n",
       "  0.5251082117448248),\n",
       " ('Grid_GBM_py_65_sid_be2c_model_python_1507067122023_1_model_87',\n",
       "  0.5251828923012749),\n",
       " ('Grid_GBM_py_65_sid_be2c_model_python_1507067122023_1_model_44',\n",
       "  0.5260783132930181),\n",
       " ('Grid_GBM_py_65_sid_be2c_model_python_1507067122023_1_model_226',\n",
       "  0.5283238682082384),\n",
       " ('Grid_GBM_py_65_sid_be2c_model_python_1507067122023_1_model_156',\n",
       "  0.5284547573366978)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get top 5 models\n",
    "top_models = pickle.load(open(\"meanClassError.pkl\", \"rb\"))[:5]\n",
    "top_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tuning was not hugely successful as the validation set improved only by 1/100. The compute time for the grid search was 5 hours on a 64 CPU virtual machine. In other words it was a computationally heavy exercise. I will consider using LightGBM in future iterations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get the scoring history\n",
    "scoreHistory = pickle.load(open(\"tuneGridScoreHistory.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>duration</th>\n",
       "      <th>number_of_trees</th>\n",
       "      <th>training_rmse</th>\n",
       "      <th>training_logloss</th>\n",
       "      <th>training_classification_error</th>\n",
       "      <th>validation_rmse</th>\n",
       "      <th>validation_logloss</th>\n",
       "      <th>validation_classification_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>2017-10-03 22:13:26</td>\n",
       "      <td>27 min 50.860 sec</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.879943</td>\n",
       "      <td>2.428884</td>\n",
       "      <td>0.874971</td>\n",
       "      <td>0.812499</td>\n",
       "      <td>1.809797</td>\n",
       "      <td>0.675683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>2017-10-03 22:13:26</td>\n",
       "      <td>27 min 51.067 sec</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.865411</td>\n",
       "      <td>2.253363</td>\n",
       "      <td>0.872023</td>\n",
       "      <td>0.795429</td>\n",
       "      <td>1.716133</td>\n",
       "      <td>0.673054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>2017-10-03 22:13:26</td>\n",
       "      <td>27 min 51.177 sec</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.856652</td>\n",
       "      <td>2.192316</td>\n",
       "      <td>0.868376</td>\n",
       "      <td>0.784767</td>\n",
       "      <td>1.669535</td>\n",
       "      <td>0.671189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>2017-10-03 22:13:26</td>\n",
       "      <td>27 min 51.305 sec</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.846979</td>\n",
       "      <td>2.098468</td>\n",
       "      <td>0.856999</td>\n",
       "      <td>0.776467</td>\n",
       "      <td>1.630820</td>\n",
       "      <td>0.665677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>2017-10-03 22:13:26</td>\n",
       "      <td>27 min 51.448 sec</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.833945</td>\n",
       "      <td>2.002353</td>\n",
       "      <td>0.823133</td>\n",
       "      <td>0.763019</td>\n",
       "      <td>1.575668</td>\n",
       "      <td>0.639732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td>2017-10-03 22:13:26</td>\n",
       "      <td>27 min 51.598 sec</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.827643</td>\n",
       "      <td>1.967003</td>\n",
       "      <td>0.776502</td>\n",
       "      <td>0.755782</td>\n",
       "      <td>1.548408</td>\n",
       "      <td>0.598525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "      <td>2017-10-03 22:13:27</td>\n",
       "      <td>27 min 51.765 sec</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.822578</td>\n",
       "      <td>1.932854</td>\n",
       "      <td>0.755042</td>\n",
       "      <td>0.751599</td>\n",
       "      <td>1.532444</td>\n",
       "      <td>0.580549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td></td>\n",
       "      <td>2017-10-03 22:13:27</td>\n",
       "      <td>27 min 51.925 sec</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.817469</td>\n",
       "      <td>1.905423</td>\n",
       "      <td>0.724240</td>\n",
       "      <td>0.746540</td>\n",
       "      <td>1.514487</td>\n",
       "      <td>0.556215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td></td>\n",
       "      <td>2017-10-03 22:13:27</td>\n",
       "      <td>27 min 52.122 sec</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.806715</td>\n",
       "      <td>1.840441</td>\n",
       "      <td>0.686929</td>\n",
       "      <td>0.738324</td>\n",
       "      <td>1.484391</td>\n",
       "      <td>0.525945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td></td>\n",
       "      <td>2017-10-03 22:13:27</td>\n",
       "      <td>27 min 52.304 sec</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.801000</td>\n",
       "      <td>1.813373</td>\n",
       "      <td>0.668851</td>\n",
       "      <td>0.732866</td>\n",
       "      <td>1.466239</td>\n",
       "      <td>0.513481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td></td>\n",
       "      <td>2017-10-03 22:13:27</td>\n",
       "      <td>27 min 52.499 sec</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.794310</td>\n",
       "      <td>1.781981</td>\n",
       "      <td>0.658259</td>\n",
       "      <td>0.726400</td>\n",
       "      <td>1.444923</td>\n",
       "      <td>0.503052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td></td>\n",
       "      <td>2017-10-03 22:13:28</td>\n",
       "      <td>27 min 52.740 sec</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.784782</td>\n",
       "      <td>1.732827</td>\n",
       "      <td>0.643860</td>\n",
       "      <td>0.719953</td>\n",
       "      <td>1.423616</td>\n",
       "      <td>0.494234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td></td>\n",
       "      <td>2017-10-03 22:13:28</td>\n",
       "      <td>27 min 53.010 sec</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.777236</td>\n",
       "      <td>1.693281</td>\n",
       "      <td>0.633162</td>\n",
       "      <td>0.716025</td>\n",
       "      <td>1.410161</td>\n",
       "      <td>0.491945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td></td>\n",
       "      <td>2017-10-03 22:13:28</td>\n",
       "      <td>27 min 53.245 sec</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.773288</td>\n",
       "      <td>1.674054</td>\n",
       "      <td>0.624064</td>\n",
       "      <td>0.713734</td>\n",
       "      <td>1.402589</td>\n",
       "      <td>0.491012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td></td>\n",
       "      <td>2017-10-03 22:13:28</td>\n",
       "      <td>27 min 53.494 sec</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.767257</td>\n",
       "      <td>1.648166</td>\n",
       "      <td>0.609432</td>\n",
       "      <td>0.709562</td>\n",
       "      <td>1.389952</td>\n",
       "      <td>0.487960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td></td>\n",
       "      <td>2017-10-03 22:13:29</td>\n",
       "      <td>27 min 53.798 sec</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.760689</td>\n",
       "      <td>1.617576</td>\n",
       "      <td>0.589329</td>\n",
       "      <td>0.706414</td>\n",
       "      <td>1.379918</td>\n",
       "      <td>0.482873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td></td>\n",
       "      <td>2017-10-03 22:13:29</td>\n",
       "      <td>27 min 54.057 sec</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.754358</td>\n",
       "      <td>1.589175</td>\n",
       "      <td>0.555368</td>\n",
       "      <td>0.703819</td>\n",
       "      <td>1.371927</td>\n",
       "      <td>0.476174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td></td>\n",
       "      <td>2017-10-03 22:13:29</td>\n",
       "      <td>27 min 54.386 sec</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.750725</td>\n",
       "      <td>1.572822</td>\n",
       "      <td>0.534862</td>\n",
       "      <td>0.702261</td>\n",
       "      <td>1.367347</td>\n",
       "      <td>0.474987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td></td>\n",
       "      <td>2017-10-03 22:13:30</td>\n",
       "      <td>27 min 54.761 sec</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.745355</td>\n",
       "      <td>1.549996</td>\n",
       "      <td>0.507019</td>\n",
       "      <td>0.700406</td>\n",
       "      <td>1.361726</td>\n",
       "      <td>0.469306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td></td>\n",
       "      <td>2017-10-03 22:13:34</td>\n",
       "      <td>27 min 58.767 sec</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.637739</td>\n",
       "      <td>1.184451</td>\n",
       "      <td>0.370602</td>\n",
       "      <td>0.659335</td>\n",
       "      <td>1.263329</td>\n",
       "      <td>0.441157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td></td>\n",
       "      <td>2017-10-03 22:13:43</td>\n",
       "      <td>28 min  8.295 sec</td>\n",
       "      <td>156.0</td>\n",
       "      <td>0.586231</td>\n",
       "      <td>1.015452</td>\n",
       "      <td>0.316273</td>\n",
       "      <td>0.647020</td>\n",
       "      <td>1.243940</td>\n",
       "      <td>0.437426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td></td>\n",
       "      <td>2017-10-03 22:13:58</td>\n",
       "      <td>28 min 23.178 sec</td>\n",
       "      <td>300.0</td>\n",
       "      <td>0.568250</td>\n",
       "      <td>0.957263</td>\n",
       "      <td>0.299277</td>\n",
       "      <td>0.643811</td>\n",
       "      <td>1.240676</td>\n",
       "      <td>0.435560</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                timestamp           duration  number_of_trees  training_rmse  \\\n",
       "0     2017-10-03 22:13:26  27 min 50.860 sec              0.0       0.879943   \n",
       "1     2017-10-03 22:13:26  27 min 51.067 sec              1.0       0.865411   \n",
       "2     2017-10-03 22:13:26  27 min 51.177 sec              2.0       0.856652   \n",
       "3     2017-10-03 22:13:26  27 min 51.305 sec              3.0       0.846979   \n",
       "4     2017-10-03 22:13:26  27 min 51.448 sec              4.0       0.833945   \n",
       "5     2017-10-03 22:13:26  27 min 51.598 sec              5.0       0.827643   \n",
       "6     2017-10-03 22:13:27  27 min 51.765 sec              6.0       0.822578   \n",
       "7     2017-10-03 22:13:27  27 min 51.925 sec              7.0       0.817469   \n",
       "8     2017-10-03 22:13:27  27 min 52.122 sec              8.0       0.806715   \n",
       "9     2017-10-03 22:13:27  27 min 52.304 sec              9.0       0.801000   \n",
       "10    2017-10-03 22:13:27  27 min 52.499 sec             10.0       0.794310   \n",
       "11    2017-10-03 22:13:28  27 min 52.740 sec             11.0       0.784782   \n",
       "12    2017-10-03 22:13:28  27 min 53.010 sec             12.0       0.777236   \n",
       "13    2017-10-03 22:13:28  27 min 53.245 sec             13.0       0.773288   \n",
       "14    2017-10-03 22:13:28  27 min 53.494 sec             14.0       0.767257   \n",
       "15    2017-10-03 22:13:29  27 min 53.798 sec             15.0       0.760689   \n",
       "16    2017-10-03 22:13:29  27 min 54.057 sec             16.0       0.754358   \n",
       "17    2017-10-03 22:13:29  27 min 54.386 sec             17.0       0.750725   \n",
       "18    2017-10-03 22:13:30  27 min 54.761 sec             18.0       0.745355   \n",
       "19    2017-10-03 22:13:34  27 min 58.767 sec             60.0       0.637739   \n",
       "20    2017-10-03 22:13:43  28 min  8.295 sec            156.0       0.586231   \n",
       "21    2017-10-03 22:13:58  28 min 23.178 sec            300.0       0.568250   \n",
       "\n",
       "    training_logloss  training_classification_error  validation_rmse  \\\n",
       "0           2.428884                       0.874971         0.812499   \n",
       "1           2.253363                       0.872023         0.795429   \n",
       "2           2.192316                       0.868376         0.784767   \n",
       "3           2.098468                       0.856999         0.776467   \n",
       "4           2.002353                       0.823133         0.763019   \n",
       "5           1.967003                       0.776502         0.755782   \n",
       "6           1.932854                       0.755042         0.751599   \n",
       "7           1.905423                       0.724240         0.746540   \n",
       "8           1.840441                       0.686929         0.738324   \n",
       "9           1.813373                       0.668851         0.732866   \n",
       "10          1.781981                       0.658259         0.726400   \n",
       "11          1.732827                       0.643860         0.719953   \n",
       "12          1.693281                       0.633162         0.716025   \n",
       "13          1.674054                       0.624064         0.713734   \n",
       "14          1.648166                       0.609432         0.709562   \n",
       "15          1.617576                       0.589329         0.706414   \n",
       "16          1.589175                       0.555368         0.703819   \n",
       "17          1.572822                       0.534862         0.702261   \n",
       "18          1.549996                       0.507019         0.700406   \n",
       "19          1.184451                       0.370602         0.659335   \n",
       "20          1.015452                       0.316273         0.647020   \n",
       "21          0.957263                       0.299277         0.643811   \n",
       "\n",
       "    validation_logloss  validation_classification_error  \n",
       "0             1.809797                         0.675683  \n",
       "1             1.716133                         0.673054  \n",
       "2             1.669535                         0.671189  \n",
       "3             1.630820                         0.665677  \n",
       "4             1.575668                         0.639732  \n",
       "5             1.548408                         0.598525  \n",
       "6             1.532444                         0.580549  \n",
       "7             1.514487                         0.556215  \n",
       "8             1.484391                         0.525945  \n",
       "9             1.466239                         0.513481  \n",
       "10            1.444923                         0.503052  \n",
       "11            1.423616                         0.494234  \n",
       "12            1.410161                         0.491945  \n",
       "13            1.402589                         0.491012  \n",
       "14            1.389952                         0.487960  \n",
       "15            1.379918                         0.482873  \n",
       "16            1.371927                         0.476174  \n",
       "17            1.367347                         0.474987  \n",
       "18            1.361726                         0.469306  \n",
       "19            1.263329                         0.441157  \n",
       "20            1.243940                         0.437426  \n",
       "21            1.240676                         0.435560  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#look at the scoring history for best performing model\n",
    "topScore = scoreHistory['Grid_GBM_py_65_sid_be2c_model_python_1507067122023_1_model_29']\n",
    "topScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#inspect the model\n",
    "topMod = h2o.load_model('/home/ec2-user/finalGaProject/Grid_GBM_py_65_sid_be2c_model_python_1507067122023_1_model_29')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Details\n",
      "=============\n",
      "H2OGradientBoostingEstimator :  Gradient Boosting Machine\n",
      "Model Key:  Grid_GBM_py_65_sid_be2c_model_python_1507067122023_1_model_29\n",
      "\n",
      "\n",
      "ModelMetricsMultinomial: gbm\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.3229076198566854\n",
      "RMSE: 0.5682496105204872\n",
      "LogLoss: 0.9572627489489983\n",
      "Mean Per-Class Error: 0.2992520893570521\n",
      "Confusion Matrix: Row labels: Actual class; Column labels: Predicted class\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>1</b></td>\n",
       "<td><b>2</b></td>\n",
       "<td><b>3</b></td>\n",
       "<td><b>4</b></td>\n",
       "<td><b>5</b></td>\n",
       "<td><b>6</b></td>\n",
       "<td><b>7</b></td>\n",
       "<td><b>8</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>6197.0</td>\n",
       "<td>496.0</td>\n",
       "<td>65.0</td>\n",
       "<td>186.0</td>\n",
       "<td>500.0</td>\n",
       "<td>1407.0</td>\n",
       "<td>790.0</td>\n",
       "<td>2133.0</td>\n",
       "<td>0.4736708</td>\n",
       "<td>5,577 / 11,774</td></tr>\n",
       "<tr><td>282.0</td>\n",
       "<td>6049.0</td>\n",
       "<td>87.0</td>\n",
       "<td>171.0</td>\n",
       "<td>723.0</td>\n",
       "<td>1570.0</td>\n",
       "<td>748.0</td>\n",
       "<td>2160.0</td>\n",
       "<td>0.4869381</td>\n",
       "<td>5,741 / 11,790</td></tr>\n",
       "<tr><td>58.0</td>\n",
       "<td>194.0</td>\n",
       "<td>9505.0</td>\n",
       "<td>658.0</td>\n",
       "<td>230.0</td>\n",
       "<td>597.0</td>\n",
       "<td>173.0</td>\n",
       "<td>388.0</td>\n",
       "<td>0.1946963</td>\n",
       "<td>2,298 / 11,803</td></tr>\n",
       "<tr><td>14.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>10006.0</td>\n",
       "<td>0.0</td>\n",
       "<td>391.0</td>\n",
       "<td>187.0</td>\n",
       "<td>1170.0</td>\n",
       "<td>0.1497281</td>\n",
       "<td>1,762 / 11,768</td></tr>\n",
       "<tr><td>105.0</td>\n",
       "<td>387.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>8180.0</td>\n",
       "<td>1492.0</td>\n",
       "<td>551.0</td>\n",
       "<td>1077.0</td>\n",
       "<td>0.3063094</td>\n",
       "<td>3,612 / 11,792</td></tr>\n",
       "<tr><td>142.0</td>\n",
       "<td>220.0</td>\n",
       "<td>4.0</td>\n",
       "<td>9.0</td>\n",
       "<td>287.0</td>\n",
       "<td>7881.0</td>\n",
       "<td>1171.0</td>\n",
       "<td>2046.0</td>\n",
       "<td>0.3298469</td>\n",
       "<td>3,879 / 11,760</td></tr>\n",
       "<tr><td>41.0</td>\n",
       "<td>21.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>48.0</td>\n",
       "<td>1070.0</td>\n",
       "<td>7084.0</td>\n",
       "<td>3571.0</td>\n",
       "<td>0.4014364</td>\n",
       "<td>4,751 / 11,835</td></tr>\n",
       "<tr><td>14.0</td>\n",
       "<td>9.0</td>\n",
       "<td>0.0</td>\n",
       "<td>5.0</td>\n",
       "<td>14.0</td>\n",
       "<td>233.0</td>\n",
       "<td>331.0</td>\n",
       "<td>11186.0</td>\n",
       "<td>0.0513908</td>\n",
       "<td>606 / 11,792</td></tr>\n",
       "<tr><td>6853.0</td>\n",
       "<td>7376.0</td>\n",
       "<td>9661.0</td>\n",
       "<td>11035.0</td>\n",
       "<td>9982.0</td>\n",
       "<td>14641.0</td>\n",
       "<td>11035.0</td>\n",
       "<td>23731.0</td>\n",
       "<td>0.2992769</td>\n",
       "<td>28,226 / 94,314</td></tr></table></div>"
      ],
      "text/plain": [
       "1     2     3     4      5     6      7      8      Error      Rate\n",
       "----  ----  ----  -----  ----  -----  -----  -----  ---------  ---------------\n",
       "6197  496   65    186    500   1407   790    2133   0.473671   5,577 / 11,774\n",
       "282   6049  87    171    723   1570   748    2160   0.486938   5,741 / 11,790\n",
       "58    194   9505  658    230   597    173    388    0.194696   2,298 / 11,803\n",
       "14    0     0     10006  0     391    187    1170   0.149728   1,762 / 11,768\n",
       "105   387   0     0      8180  1492   551    1077   0.306309   3,612 / 11,792\n",
       "142   220   4     9      287   7881   1171   2046   0.329847   3,879 / 11,760\n",
       "41    21    0     0      48    1070   7084   3571   0.401436   4,751 / 11,835\n",
       "14    9     0     5      14    233    331    11186  0.0513908  606 / 11,792\n",
       "6853  7376  9661  11035  9982  14641  11035  23731  0.299277   28,226 / 94,314"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-8 Hit Ratios: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>k</b></td>\n",
       "<td><b>hit_ratio</b></td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>0.7007231</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.8503721</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.9114766</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.9534428</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.9759845</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.9907013</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.9992366</td></tr>\n",
       "<tr><td>8</td>\n",
       "<td>1.0</td></tr></table></div>"
      ],
      "text/plain": [
       "k    hit_ratio\n",
       "---  -----------\n",
       "1    0.700723\n",
       "2    0.850372\n",
       "3    0.911477\n",
       "4    0.953443\n",
       "5    0.975984\n",
       "6    0.990701\n",
       "7    0.999237\n",
       "8    1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ModelMetricsMultinomial: gbm\n",
      "** Reported on validation data. **\n",
      "\n",
      "MSE: 0.4144929666013407\n",
      "RMSE: 0.643811281822042\n",
      "LogLoss: 1.2406756451508365\n",
      "Mean Per-Class Error: 0.5251082117448248\n",
      "Confusion Matrix: Row labels: Actual class; Column labels: Predicted class\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>1</b></td>\n",
       "<td><b>2</b></td>\n",
       "<td><b>3</b></td>\n",
       "<td><b>4</b></td>\n",
       "<td><b>5</b></td>\n",
       "<td><b>6</b></td>\n",
       "<td><b>7</b></td>\n",
       "<td><b>8</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>251.0</td>\n",
       "<td>167.0</td>\n",
       "<td>26.0</td>\n",
       "<td>20.0</td>\n",
       "<td>107.0</td>\n",
       "<td>250.0</td>\n",
       "<td>128.0</td>\n",
       "<td>275.0</td>\n",
       "<td>0.7949346</td>\n",
       "<td>973 / 1,224</td></tr>\n",
       "<tr><td>122.0</td>\n",
       "<td>308.0</td>\n",
       "<td>17.0</td>\n",
       "<td>35.0</td>\n",
       "<td>160.0</td>\n",
       "<td>274.0</td>\n",
       "<td>130.0</td>\n",
       "<td>276.0</td>\n",
       "<td>0.7670197</td>\n",
       "<td>1,014 / 1,322</td></tr>\n",
       "<tr><td>17.0</td>\n",
       "<td>16.0</td>\n",
       "<td>66.0</td>\n",
       "<td>55.0</td>\n",
       "<td>12.0</td>\n",
       "<td>13.0</td>\n",
       "<td>1.0</td>\n",
       "<td>7.0</td>\n",
       "<td>0.6470588</td>\n",
       "<td>121 / 187</td></tr>\n",
       "<tr><td>18.0</td>\n",
       "<td>6.0</td>\n",
       "<td>16.0</td>\n",
       "<td>204.0</td>\n",
       "<td>0.0</td>\n",
       "<td>26.0</td>\n",
       "<td>5.0</td>\n",
       "<td>27.0</td>\n",
       "<td>0.3245033</td>\n",
       "<td>98 / 302</td></tr>\n",
       "<tr><td>51.0</td>\n",
       "<td>114.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>539.0</td>\n",
       "<td>203.0</td>\n",
       "<td>45.0</td>\n",
       "<td>112.0</td>\n",
       "<td>0.4938967</td>\n",
       "<td>526 / 1,065</td></tr>\n",
       "<tr><td>96.0</td>\n",
       "<td>109.0</td>\n",
       "<td>1.0</td>\n",
       "<td>5.0</td>\n",
       "<td>104.0</td>\n",
       "<td>1201.0</td>\n",
       "<td>287.0</td>\n",
       "<td>494.0</td>\n",
       "<td>0.4771441</td>\n",
       "<td>1,096 / 2,297</td></tr>\n",
       "<tr><td>29.0</td>\n",
       "<td>17.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>18.0</td>\n",
       "<td>282.0</td>\n",
       "<td>627.0</td>\n",
       "<td>598.0</td>\n",
       "<td>0.6011450</td>\n",
       "<td>945 / 1,572</td></tr>\n",
       "<tr><td>10.0</td>\n",
       "<td>13.0</td>\n",
       "<td>0.0</td>\n",
       "<td>2.0</td>\n",
       "<td>8.0</td>\n",
       "<td>173.0</td>\n",
       "<td>158.0</td>\n",
       "<td>3461.0</td>\n",
       "<td>0.0951634</td>\n",
       "<td>364 / 3,825</td></tr>\n",
       "<tr><td>594.0</td>\n",
       "<td>750.0</td>\n",
       "<td>127.0</td>\n",
       "<td>322.0</td>\n",
       "<td>948.0</td>\n",
       "<td>2422.0</td>\n",
       "<td>1381.0</td>\n",
       "<td>5250.0</td>\n",
       "<td>0.4355605</td>\n",
       "<td>5,137 / 11,794</td></tr></table></div>"
      ],
      "text/plain": [
       "1    2    3    4    5    6     7     8     Error      Rate\n",
       "---  ---  ---  ---  ---  ----  ----  ----  ---------  --------------\n",
       "251  167  26   20   107  250   128   275   0.794935   973 / 1,224\n",
       "122  308  17   35   160  274   130   276   0.76702    1,014 / 1,322\n",
       "17   16   66   55   12   13    1     7     0.647059   121 / 187\n",
       "18   6    16   204  0    26    5     27    0.324503   98 / 302\n",
       "51   114  1    0    539  203   45    112   0.493897   526 / 1,065\n",
       "96   109  1    5    104  1201  287   494   0.477144   1,096 / 2,297\n",
       "29   17   0    1    18   282   627   598   0.601145   945 / 1,572\n",
       "10   13   0    2    8    173   158   3461  0.0951634  364 / 3,825\n",
       "594  750  127  322  948  2422  1381  5250  0.43556    5,137 / 11,794"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-8 Hit Ratios: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>k</b></td>\n",
       "<td><b>hit_ratio</b></td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>0.5644395</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.7502119</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.8634051</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.9302188</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.9727828</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.9922842</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.9972868</td></tr>\n",
       "<tr><td>8</td>\n",
       "<td>1.0</td></tr></table></div>"
      ],
      "text/plain": [
       "k    hit_ratio\n",
       "---  -----------\n",
       "1    0.56444\n",
       "2    0.750212\n",
       "3    0.863405\n",
       "4    0.930219\n",
       "5    0.972783\n",
       "6    0.992284\n",
       "7    0.997287\n",
       "8    1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring History: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>timestamp</b></td>\n",
       "<td><b>duration</b></td>\n",
       "<td><b>number_of_trees</b></td>\n",
       "<td><b>training_rmse</b></td>\n",
       "<td><b>training_logloss</b></td>\n",
       "<td><b>training_classification_error</b></td>\n",
       "<td><b>validation_rmse</b></td>\n",
       "<td><b>validation_logloss</b></td>\n",
       "<td><b>validation_classification_error</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-10-03 22:13:26</td>\n",
       "<td>27 min 50.860 sec</td>\n",
       "<td>0.0</td>\n",
       "<td>0.8799430</td>\n",
       "<td>2.4288837</td>\n",
       "<td>0.8749708</td>\n",
       "<td>0.8124991</td>\n",
       "<td>1.8097968</td>\n",
       "<td>0.6756826</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-10-03 22:13:26</td>\n",
       "<td>27 min 51.067 sec</td>\n",
       "<td>1.0</td>\n",
       "<td>0.8654112</td>\n",
       "<td>2.2533631</td>\n",
       "<td>0.8720232</td>\n",
       "<td>0.7954293</td>\n",
       "<td>1.7161329</td>\n",
       "<td>0.6730541</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-10-03 22:13:26</td>\n",
       "<td>27 min 51.177 sec</td>\n",
       "<td>2.0</td>\n",
       "<td>0.8566521</td>\n",
       "<td>2.1923159</td>\n",
       "<td>0.8683759</td>\n",
       "<td>0.7847667</td>\n",
       "<td>1.6695349</td>\n",
       "<td>0.6711887</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-10-03 22:13:26</td>\n",
       "<td>27 min 51.305 sec</td>\n",
       "<td>3.0</td>\n",
       "<td>0.8469787</td>\n",
       "<td>2.0984681</td>\n",
       "<td>0.8569990</td>\n",
       "<td>0.7764671</td>\n",
       "<td>1.6308202</td>\n",
       "<td>0.6656775</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-10-03 22:13:26</td>\n",
       "<td>27 min 51.448 sec</td>\n",
       "<td>4.0</td>\n",
       "<td>0.8339450</td>\n",
       "<td>2.0023528</td>\n",
       "<td>0.8231334</td>\n",
       "<td>0.7630193</td>\n",
       "<td>1.5756677</td>\n",
       "<td>0.6397321</td></tr>\n",
       "<tr><td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-10-03 22:13:29</td>\n",
       "<td>27 min 54.386 sec</td>\n",
       "<td>17.0</td>\n",
       "<td>0.7507252</td>\n",
       "<td>1.5728223</td>\n",
       "<td>0.5348623</td>\n",
       "<td>0.7022607</td>\n",
       "<td>1.3673472</td>\n",
       "<td>0.4749873</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-10-03 22:13:30</td>\n",
       "<td>27 min 54.761 sec</td>\n",
       "<td>18.0</td>\n",
       "<td>0.7453550</td>\n",
       "<td>1.5499964</td>\n",
       "<td>0.5070191</td>\n",
       "<td>0.7004060</td>\n",
       "<td>1.3617261</td>\n",
       "<td>0.4693064</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-10-03 22:13:34</td>\n",
       "<td>27 min 58.767 sec</td>\n",
       "<td>60.0</td>\n",
       "<td>0.6377394</td>\n",
       "<td>1.1844511</td>\n",
       "<td>0.3706025</td>\n",
       "<td>0.6593346</td>\n",
       "<td>1.2633294</td>\n",
       "<td>0.4411565</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-10-03 22:13:43</td>\n",
       "<td>28 min  8.295 sec</td>\n",
       "<td>156.0</td>\n",
       "<td>0.5862311</td>\n",
       "<td>1.0154515</td>\n",
       "<td>0.3162733</td>\n",
       "<td>0.6470205</td>\n",
       "<td>1.2439404</td>\n",
       "<td>0.4374258</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-10-03 22:13:58</td>\n",
       "<td>28 min 23.178 sec</td>\n",
       "<td>300.0</td>\n",
       "<td>0.5682496</td>\n",
       "<td>0.9572627</td>\n",
       "<td>0.2992769</td>\n",
       "<td>0.6438113</td>\n",
       "<td>1.2406756</td>\n",
       "<td>0.4355605</td></tr></table></div>"
      ],
      "text/plain": [
       "     timestamp            duration           number_of_trees    training_rmse       training_logloss    training_classification_error    validation_rmse     validation_logloss    validation_classification_error\n",
       "---  -------------------  -----------------  -----------------  ------------------  ------------------  -------------------------------  ------------------  --------------------  ---------------------------------\n",
       "     2017-10-03 22:13:26  27 min 50.860 sec  0.0                0.8799430173404723  2.4288836969098986  0.8749708420807091               0.8124991395664735  1.809796830501791     0.6756825504493811\n",
       "     2017-10-03 22:13:26  27 min 51.067 sec  1.0                0.8654111813069534  2.2533630973091876  0.8720232415123947               0.7954292696878829  1.7161328592444982    0.6730540953026963\n",
       "     2017-10-03 22:13:26  27 min 51.177 sec  2.0                0.8566521155119128  2.192315897528783   0.8683758508810993               0.7847666531232264  1.6695348620239334    0.6711887400373071\n",
       "     2017-10-03 22:13:26  27 min 51.305 sec  3.0                0.8469786742955381  2.0984681106674254  0.8569989609177853               0.7764670738735926  1.6308202028765355    0.6656774631168391\n",
       "     2017-10-03 22:13:26  27 min 51.448 sec  4.0                0.8339450008823592  2.0023527717765655  0.8231333630213966               0.763019315435895   1.57566767515993      0.6397320671527895\n",
       "---  ---                  ---                ---                ---                 ---                 ---                              ---                 ---                   ---\n",
       "     2017-10-03 22:13:29  27 min 54.386 sec  17.0               0.7507252268818985  1.5728222955731004  0.5348622685921496               0.702260731314099   1.3673471523415213    0.47498728166864507\n",
       "     2017-10-03 22:13:30  27 min 54.761 sec  18.0               0.7453549938422883  1.5499963835484911  0.5070191063892954               0.700405966739296   1.3617260522618249    0.46930642699677805\n",
       "     2017-10-03 22:13:34  27 min 58.767 sec  60.0               0.6377393846415194  1.1844511333434686  0.37060245562694827              0.6593345649999536  1.2633294264129407    0.4411565202645413\n",
       "     2017-10-03 22:13:43  28 min  8.295 sec  156.0              0.5862311464383407  1.0154515156369954  0.3162732998282333               0.647020483898476   1.2439403695432505    0.43742580973376294\n",
       "     2017-10-03 22:13:58  28 min 23.178 sec  300.0              0.5682496105204872  0.9572627489489983  0.29927688360158616              0.643811281822042   1.2406756451508365    0.43556045446837377"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "See the whole table with table.as_data_frame()\n",
      "Variable Importances: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>variable</b></td>\n",
       "<td><b>relative_importance</b></td>\n",
       "<td><b>scaled_importance</b></td>\n",
       "<td><b>percentage</b></td></tr>\n",
       "<tr><td>Medical_History_15</td>\n",
       "<td>61214.5039062</td>\n",
       "<td>1.0</td>\n",
       "<td>0.2581582</td></tr>\n",
       "<tr><td>Family_Hist_3</td>\n",
       "<td>25733.4296875</td>\n",
       "<td>0.4203813</td>\n",
       "<td>0.1085249</td></tr>\n",
       "<tr><td>Family_Hist_5</td>\n",
       "<td>22521.5449219</td>\n",
       "<td>0.3679119</td>\n",
       "<td>0.0949795</td></tr>\n",
       "<tr><td>BMI</td>\n",
       "<td>22199.1054688</td>\n",
       "<td>0.3626445</td>\n",
       "<td>0.0936197</td></tr>\n",
       "<tr><td>Product_Info_4</td>\n",
       "<td>8978.0693359</td>\n",
       "<td>0.1466657</td>\n",
       "<td>0.0378630</td></tr>\n",
       "<tr><td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td></tr>\n",
       "<tr><td>Medical_Keyword_27</td>\n",
       "<td>36.2540741</td>\n",
       "<td>0.0005922</td>\n",
       "<td>0.0001529</td></tr>\n",
       "<tr><td>Medical_History_22</td>\n",
       "<td>34.4385834</td>\n",
       "<td>0.0005626</td>\n",
       "<td>0.0001452</td></tr>\n",
       "<tr><td>Medical_Keyword_44</td>\n",
       "<td>19.0572853</td>\n",
       "<td>0.0003113</td>\n",
       "<td>0.0000804</td></tr>\n",
       "<tr><td>Medical_Keyword_28</td>\n",
       "<td>18.9106522</td>\n",
       "<td>0.0003089</td>\n",
       "<td>0.0000798</td></tr>\n",
       "<tr><td>Medical_Keyword_13</td>\n",
       "<td>15.6594152</td>\n",
       "<td>0.0002558</td>\n",
       "<td>0.0000660</td></tr></table></div>"
      ],
      "text/plain": [
       "variable            relative_importance    scaled_importance       percentage\n",
       "------------------  ---------------------  ----------------------  ----------------------\n",
       "Medical_History_15  61214.50390625         1.0                     0.2581582199608022\n",
       "Family_Hist_3       25733.4296875          0.42038125028197143     0.10852487527769022\n",
       "Family_Hist_5       22521.544921875        0.367911907876714       0.09497948323983513\n",
       "BMI                 22199.10546875         0.3626445376858387      0.09361966832748417\n",
       "Product_Info_4      8978.0693359375        0.1466657207528368      0.037862961398820436\n",
       "---                 ---                    ---                     ---\n",
       "Medical_Keyword_27  36.25407409667969      0.0005922464740088851   0.00015289329550819528\n",
       "Medical_History_22  34.43858337402344      0.0005625886215914797   0.00014523687712025772\n",
       "Medical_Keyword_44  19.05728530883789      0.00031131977052405944  8.03697577970966e-05\n",
       "Medical_Keyword_28  18.91065216064453      0.00030892437174049784  7.975136591103607e-05\n",
       "Medical_Keyword_13  15.659415245056152     0.0002558121727007466   6.604001514873006e-05"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "See the whole table with table.as_data_frame()\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topMod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the end of the tuning. Next I inspect the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Export File progress: |███████████████████████████████████████████████████| 100%\n",
      "Export File progress: |███████████████████████████████████████████████████| 100%\n",
      "Export File progress: |███████████████████████████████████████████████████| 100%\n",
      "Export File progress: |███████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "h2o.export_file(train60, path = \"/home/ec2-user/finalGaProject/h2oData/train60.h20\", force=True)\n",
    "h2o.export_file(train80, path='/home/ec2-user/finalGaProject/h2oData/train80.h20', force=True)\n",
    "h2o.export_file(valid, path='/home/ec2-user/finalGaProject/h2oData/valid.h20', force=True)\n",
    "h2o.export_file(test, path='/home/ec2-user/finalGaProject/h2oData/test.h20', force=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
